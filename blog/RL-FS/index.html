<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Feature Selection Using RL &#8211; Golnar k. Mahani</title>
<meta name="description" content="In this post the research works of S. M. Hazrati Fard et al. on the application of Reinforcement Learning to Feature Selection have been reviewed.

">
<meta name="keywords" content="Reinforcement Learning, Feature Selection, MDP, Temporal Difference">


<!-- Twitter Cards -->
<meta name="twitter:title" content="Feature Selection Using RL">
<meta name="twitter:description" content="In this post the research works of S. M. Hazrati Fard et al. on the application of Reinforcement Learning to Feature Selection have been reviewed.

">



<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://golnarMahani.github.io/images/site-logo.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Feature Selection Using RL">
<meta property="og:description" content="In this post the research works of S. M. Hazrati Fard et al. on the application of Reinforcement Learning to Feature Selection have been reviewed.

">
<meta property="og:url" content="https://golnarMahani.github.io/blog/RL-FS/">
<meta property="og:site_name" content="Golnar k. Mahani">





<link rel="canonical" href="https://golnarMahani.github.io/blog/RL-FS/">
<!-- <link href="https://golnarMahani.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Golnar k. Mahani Feed"> -->

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="https://golnarMahani.github.io/assets/css/main.css">
<!-- Webfonts -->
<script src="https://use.edgefonts.net/source-sans-pro:n2,i2,n3,i3,n4,i4,n6,i6,n7,i7,n9,i9;source-code-pro:n4,n7;volkhov.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
  <script src="https://golnarMahani.github.io/assets/js/vendor/html5shiv.min.js"></script>
  <script src="https://golnarMahani.github.io/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="https://golnarMahani.github.io/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>


<!-- MathJax -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://golnarMahani.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://golnarMahani.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://golnarMahani.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://golnarMahani.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://golnarMahani.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://golnarMahani.github.io/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body id="post">

<div class="navigation-wrapper">
	<nav role="navigation" id="site-nav" class="animated drop">
	    <ul>
      
		    
		    <li><a href="https://golnarMahani.github.io/about/" >About</a></li>
		  
		    
		    <li><a href="https://golnarMahani.github.io/cv/" >My CV</a></li>
		  
		    
		    <li><a href="https://golnarMahani.github.io/blog/" >Blog</a></li>
		  
	    </ul>
	</nav>
</div><!-- /.navigation-wrapper -->

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->



<div class="js-menu-screen menu-screen"></div>


<div id="main" role="main">
  <article class="hentry">
    
    <div class="entry-wrapper">
      <header class="entry-header">
        <ul class="entry-tags">
          <li><a href="https://golnarMahani.github.io/tags/#Reinforcement Learning" title="Pages tagged Reinforcement Learning">Reinforcement Learning</a></li><li><a href="https://golnarMahani.github.io/tags/#Feature Selection" title="Pages tagged Feature Selection">Feature Selection</a></li><li><a href="https://golnarMahani.github.io/tags/#MDP" title="Pages tagged MDP">MDP</a></li><li><a href="https://golnarMahani.github.io/tags/#Temporal Difference" title="Pages tagged Temporal Difference">Temporal Difference</a></li>
        </ul>
        
          <h1 class="entry-title">Feature Selection Using RL</h1>
        
      </header>
      <footer class="entry-meta">
        
        
          <img src="https://golnarMahani.github.io/images/golnar-mahani-photo.jpg" class="bio-photo" alt="Golnar Mahani bio photo"></a>
        
        <span class="author vcard">By <span class="fn">Golnar Mahani</span></span>
        <span class="entry-date date published"><time datetime="2017-08-15T00:00:00+04:30"><i class="fa fa-calendar-o"></i> August 15, 2017</time></span>
        
        
        
        </footer>
      <div class="entry-content">
        <p>In this post the research works of S. M. Hazrati Fard et al. on the application of Reinforcement Learning to Feature Selection have been reviewed.</p>

<p>As mentioned in the Data Mining: Concepts and Techniques book by Jiawei Han et al, data mining could be seen as a step in the knowledge discovery process. This process could be considered as a sequence of steps, namely: Data Cleaning, Data Integration, Data Selection, Data Transformation, Data Mining, Pattern Evaluation, and Knowledge Presentation.<br />
In the data selection phase of the knowledge discovery process, relevant data are retrieved to help better extract knowledge from Data. Feature selection techniques are advantageous in many different aspects. For one, this step becomes more important when faced with the problem of curse of dimensionality and to improve the performance of the KDD process, feature selection techniques could be very beneficial.</p>

<h3 id="the-application-of-rl-to-feature-selection">The Application of RL to Feature Selection</h3>
<p>In S. M. Hazrati Fard et al. research, a method has been introduced to address the Feature Selection step of KDD process for classification problems. This method was inspired from the FUSE algorithm proposed by R. Gaudel et al.<br />
R. Gaudel et al. defined the feature selection as a Reinforcement Learning problem. The optimization is done using the UCT Monte-Carlo tree search algorithm with a bandit-based phase and a random phase which are in fact the exploration and exploitation phases of the algorithm.</p>

<h3 id="rl-framework">RL Framework</h3>
<p>Inspired from FUSE, S. M. Hazrati Fard et al. suggested taking advantage of the Temporal Difference method for traversing the state space and selecting the best next feature. 
Defining feature selection as an RL problem, the state space is introduced as a Markov decision process. As shown in the following figure, a subset of features, taking a new feature in a state and selecting the best action in the current state to reach the best regions are referred to as state, action and policy; respectively.</p>
<figure>
	<img src="/images/RL-Framework.png" alt="image" />
	<figcaption>RLFS notations.</figcaption>
</figure>
<p>In this research TD(0) has been used and the reward function is achieved by evaluating the features using a Gaussian SVM. Since SVM is used in the proposed method many times, the instance reduction is done to reduce the complexity of SVM. 
The best next action in each state is determined by using the average of rewards (AOR) of each feature each time it is selected in the specific state. 
For each iteration, if in m consecutive times the value of the state declines, that iteration should be terminated and another episode initiates. 
While traversing the state space, if a state has been visited before, the exploitation should be done; otherwise the exploration function should be applied to that state.</p>

<p>Finally, after all iterations, the best features should be selected. S. M. Hazrati Fard et al. proposed two methods for selecting the final features. The first method is a filter-based method, in which the obtained AORs are sorted in a descending order and the top-rank features are selected. The second method is a wrapper-based selection method in which the graph of the traversed spaces is searched for finding the best nodes with final rewards.</p>

<p>Although the evaluation results show that the proposed method is suitable for different kinds of data specifically for large datasets, still this method has the potential to have a better performance. for future works, this method can be extended to be used for multi-class data. More study can be done on the termination conditions and the convergence of the algorithm. Furthermore, the impact of utilizing some filter methods such as correlation based feature selection in the process of selecting the best action in each state should be studied.</p>

<h3 id="references">References</h3>
<hr />
<blockquote>
  <p><a href="http://dx.doi.org/10.1016/j.camwa.2013.06.031">S. M. H. Fard, A. Hamzeh, and S. Hashemi</a>, “Using reinforcement learning to find an optimal set of features,” Comput. Math. with Appl., vol. 66, no. 10, pp. 1892–1904, 2013.</p>

  <p><a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=pQws07tdpjoC&amp;oi=fnd&amp;pg=PP1&amp;dq=Data+Mining:+Concepts+and+Techniques,+3rd&amp;ots=tzDv2Tpy-2&amp;sig=ZlD0JVrZ7SLyixGcshIWLhSME1g">J. Han, M. Kamber, J. Pei</a>, Data Mining: Concepts and Techniques, 3rd ed., Morgan Kaufman, 2011.</p>

  <p><a href="https://hal.inria.fr/inria-00484049/">R. Gaudel, M. Sebag</a>, Feature selection as a one-player game, in: ICML, 2010, pp. 359–366.</p>

  <p><a href="https://doi.org/10.1109/FSKD.2012.6234170">S.M. Hazrati, A. Hamzeh, S. Hashemi</a>, A game theoretic framework for feature selection, in: FSKD, 2012, pp. 845–850.</p>

  <p><a href="http://ijmi.ir/index.php/IJMI/article/view/34">S. M. Hazrati Fard, A. Hamzeh, and S. Hashemi</a>, “A Reinforcement Learning Based Method for Feature Selection on the Imbalanced Datasets,” Iran. J. Med. Informatics, vol. 2, no. 1, 2013.</p>

  <p><a href="https://doi.org/10.1109/AISP.2012.6313777">S. M. H. Fard, A. Hamzeh, and S. Hashemi</a>, “Proposing a reinforcement learning based approach for feature selection,” in Artificial Intelligence and Signal Processing (AISP), 2012 16th CSI International Symposium on, 2012, pp. 380–385.</p>

</blockquote>


      </div><!-- /.entry-content -->
    </div><!-- /.entry-wrapper -->
    <nav class="pagination" role="navigation">
      
        <a href="https://golnarMahani.github.io/blog/warfarin-therapy-management/" class="btn" title="Warfarin Therapy Management">Previous</a>
      
      
    </nav><!-- /.pagination -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo" class="entry-wrapper">
    

<span>&copy; 2018 Golnar Mahani. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a>.</span>
<div class="social-icons">
	
	
	
	<a href="https://linkedin.com/in/golnar-k-mahani-a0020287" title="Golnar Mahani on LinkedIn" target="_blank"><i class="fa fa-linkedin-square fa-2x"></i></a>
	
	
	
	<a href="https://github.com/golnarMahani" title="Golnar Mahani on Github" target="_blank"><i class="fa fa-github-square fa-2x"></i></a>
	
  
	
  <!-- <a href="https://golnarMahani.github.io/feed.xml" title="Atom/RSS feed"><i class="fa fa-rss-square fa-2x"></i></a> -->
</div><!-- /.social-icons -->

  </footer>
</div><!-- /.footer-wrapper -->

<script type="text/javascript">
  var BASE_URL = 'https://golnarMahani.github.io';
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="https://golnarMahani.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="https://golnarMahani.github.io/assets/js/scripts.min.js"></script>




</body>
</html>
